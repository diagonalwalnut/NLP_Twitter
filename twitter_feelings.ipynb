{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258fd66e",
   "metadata": {},
   "source": [
    "https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f\n",
    "https://towardsdatascience.com/almost-real-time-twitter-sentiment-analysis-with-tweep-vader-f88ed5b93b1c\n",
    "https://python.plainenglish.io/twitter-sentiment-analysis-using-vader-tweepy-b2a62fba151e\n",
    "https://www.analyticsvidhya.com/blog/2021/06/twitter-sentiment-analysis-a-nlp-use-case-for-beginners/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1d892c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twitter\n",
      "  Downloading twitter-1.19.3-py2.py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: twitter\n",
      "Successfully installed twitter-1.19.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install vaderSentiment\n",
    "# !pip install twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "734f540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from twitter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "addf2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_vars = get_dataframe(\"twitter.pkl\")\n",
    "\n",
    "CLIENT_KEY = api_vars.client_key[0]\n",
    "CLIENT_SECRET =  api_vars.client_secret[0]\n",
    "ACCESS_TOKEN = api_vars.access_token[0]\n",
    "ACCESS_TOKEN_SECRET = api_vars.token_secret[0]\n",
    "\n",
    "TOPIC = \"Lockheed -filter:retweet\"\n",
    "\n",
    "MAX_TWEETS = 400\n",
    "TWEET_LIMIT = 100 # we can get only 100 tweet per call with standard search api\n",
    "\n",
    "PICKLE_FILENAME = \"lockheed_tweets.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0f3f0140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_generator(tweets):\n",
    "    for tweet in tweets:\n",
    "        modified_tweet= dict(tweet)\n",
    "\n",
    "        modified_tweet['user_id'] = tweet['user']['id']\n",
    "        del modified_tweet['user']\n",
    "        \n",
    "        if 'retweeted_status' in tweet:\n",
    "            modified_tweet['retweeted_status_id'] = tweet['retweeted_status']['id']\n",
    "            del modified_tweet['retweeted_status']\n",
    "        \n",
    "        yield modified_tweet\n",
    "\n",
    "def save_to_file(ts, file_name):\n",
    "    ts.to_pickle(file_name)\n",
    "    return None\n",
    "\n",
    "def get_dataframe(file_name):\n",
    "    return pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "01699b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_secret = '{}:{}'.format(CLIENT_KEY, CLIENT_SECRET).encode('ascii')\n",
    "b64_encoded_key = base64.b64encode(key_secret)\n",
    "b64_encoded_key = b64_encoded_key.decode('ascii')\n",
    "\n",
    "base_url = 'https://api.twitter.com/'\n",
    "auth_endpoint = base_url+'oauth2/token'\n",
    "\n",
    "auth_headers = { 'Authorization': 'Basic {}'.format(b64_encoded_key),\n",
    "                'Content-Type': 'application/x-www-form-urlencoded;charset=UTF-8'}\n",
    "\n",
    "auth_data = { 'grant_type': 'client_credentials'}\n",
    "\n",
    "response = requests.post(auth_endpoint, headers=auth_headers, data=auth_data)\n",
    "json_data =  response.json()\n",
    "access_token = json_data['access_token']\n",
    "\n",
    "search_headers = {'Authorization': 'Bearer {}'.format(access_token)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "54dab832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from file.\n",
      "File read. Retrieved 400 tweets.\n",
      "Min ID: 1451566522439135238.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Reading from file.\")\n",
    "    tweet_df = get_dataframe(PICKLE_FILENAME)\n",
    "    print(f\"File read. Retrieved {len(tweet_df)} tweets.\")\n",
    "except:\n",
    "    print(\"Error reading from file.\")\n",
    "    parameters = { 'q': TOPIC, 'result_type': 'all', 'count': TWEET_LIMIT }\n",
    "    search_url = base_url+'1.1/search/tweets.json'\n",
    "    response = requests.get(search_url, headers=search_headers, params=parameters)\n",
    "    print(\"Getting tweets.\")\n",
    "    tweet_response = response.json()\n",
    "    ids = [tw['id'] for tw in tweet_response['statuses']]\n",
    "    tw_ids = []\n",
    "    tw_ids += ids\n",
    "\n",
    "    temp = []\n",
    "\n",
    "    temp += tweet_response['statuses']\n",
    "    print('Total tweets retrieved= {}'.format(len(temp)))\n",
    "    \n",
    "    tweet_df = pd.DataFrame(tweet_generator(temp))\n",
    "\n",
    "min_id = tweet_df.tail(1).id.values[0]\n",
    "print(f\"Min ID: {min_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e068bf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching tweets with id  < 1451566522439135238\n",
      "Getting tweets.\n",
      "Got tweets.\n",
      "Round #0; Number of tweets: 100\n",
      "searching tweets with id  < 1451546943704940554\n",
      "Getting tweets.\n",
      "Got tweets.\n",
      "Round #1; Number of tweets: 100\n",
      "searching tweets with id  < 1451526291342217217\n",
      "Getting tweets.\n",
      "Got tweets.\n",
      "Round #2; Number of tweets: 96\n",
      "All Done.\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "\n",
    "for  i in range(MAX_TWEETS//TWEET_LIMIT -1):\n",
    "    parameters = { 'q': TOPIC, 'result_type': 'recent', 'count': TWEET_LIMIT, 'max_id': min_id}\n",
    "    print(\"searching tweets with id  < {}\".format(min_id))\n",
    "    search_url = base_url+'1.1/search/tweets.json'\n",
    "    try:\n",
    "        print(\"Getting tweets.\")\n",
    "        response = requests.get(search_url, headers=search_headers, params=parameters)\n",
    "        tweet_response = response.json()\n",
    "        print(\"Got tweets.\")\n",
    "    except:\n",
    "        print(\"Something bad happened.\")\n",
    "        break\n",
    "    \n",
    "    ids = [tw['id'] for tw in tweet_response['statuses']]\n",
    "    tw_ids += ids\n",
    "    print(f\"Round #{i}; Number of tweets: {len(tweet_response['statuses'])}\")\n",
    "    if min_id == min(ids):\n",
    "        print(\"We are not progressing.\")\n",
    "        break\n",
    "    min_id = min(ids)\n",
    "    temp += tweet_response['statuses']\n",
    "\n",
    "print(\"All Done.\")\n",
    "tweet_df = tweet_df.append(pd.DataFrame(tweet_generator(temp)), ignore_index=True)\n",
    "#save_to_file(tweet_df, PICKLE_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f1a8841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets retrieved= 696\n"
     ]
    }
   ],
   "source": [
    "print('Total tweets retrieved= {}'.format(len(tweet_df)))\n",
    "save_to_file(tweet_df, PICKLE_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3f0027ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df = get_dataframe(PICKLE_FILENAME)\n",
    "len(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "01198dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>entities</th>\n",
       "      <th>metadata</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>lang</th>\n",
       "      <th>user_id</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Oct 22 22:20:59 +0000 2021</td>\n",
       "      <td>1451674974280949761</td>\n",
       "      <td>1451674974280949761</td>\n",
       "      <td>RT @gustinicchi: Lavoratori lasciano in blocco...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'it', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>it</td>\n",
       "      <td>1397217753317224450</td>\n",
       "      <td>1.451617e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Oct 22 22:20:10 +0000 2021</td>\n",
       "      <td>1451674770676801540</td>\n",
       "      <td>1451674770676801540</td>\n",
       "      <td>‘LASER DOME’: Rafael, Lockheed Developing Next...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>873959210274443264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Oct 22 22:11:58 +0000 2021</td>\n",
       "      <td>1451672707221819392</td>\n",
       "      <td>1451672707221819392</td>\n",
       "      <td>#PlaneAlert ICAO: #AE03D5 Tail: #164598 \\nOwne...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'hashtags': [{'text': 'PlaneAlert', 'indices'...</td>\n",
       "      <td>{'iso_language_code': 'fr', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://ramonk.net/planefence\" rel=\"n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>fr</td>\n",
       "      <td>1259995501916819459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "0  Fri Oct 22 22:20:59 +0000 2021  1451674974280949761  1451674974280949761   \n",
       "1  Fri Oct 22 22:20:10 +0000 2021  1451674770676801540  1451674770676801540   \n",
       "2  Fri Oct 22 22:11:58 +0000 2021  1451672707221819392  1451672707221819392   \n",
       "\n",
       "                                                text  truncated  \\\n",
       "0  RT @gustinicchi: Lavoratori lasciano in blocco...      False   \n",
       "1  ‘LASER DOME’: Rafael, Lockheed Developing Next...       True   \n",
       "2  #PlaneAlert ICAO: #AE03D5 Tail: #164598 \\nOwne...       True   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "2  {'hashtags': [{'text': 'PlaneAlert', 'indices'...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'iso_language_code': 'it', 'result_type': 're...   \n",
       "1  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "2  {'iso_language_code': 'fr', 'result_type': 're...   \n",
       "\n",
       "                                              source  in_reply_to_status_id  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...                    NaN   \n",
       "1  <a href=\"https://mobile.twitter.com\" rel=\"nofo...                    NaN   \n",
       "2  <a href=\"https://ramonk.net/planefence\" rel=\"n...                    NaN   \n",
       "\n",
       "  in_reply_to_status_id_str  ...  favorited retweeted lang  \\\n",
       "0                      None  ...      False     False   it   \n",
       "1                      None  ...      False     False   en   \n",
       "2                      None  ...      False     False   fr   \n",
       "\n",
       "               user_id retweeted_status_id possibly_sensitive  \\\n",
       "0  1397217753317224450        1.451617e+18                NaN   \n",
       "1   873959210274443264                 NaN              False   \n",
       "2  1259995501916819459                 NaN              False   \n",
       "\n",
       "  extended_entities  quoted_status_id  quoted_status_id_str  quoted_status  \n",
       "0               NaN               NaN                   NaN            NaN  \n",
       "1               NaN               NaN                   NaN            NaN  \n",
       "2               NaN               NaN                   NaN            NaN  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b87b45a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.897, 'pos': 0.103, 'compound': 0.128}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.087, 'neu': 0.913, 'pos': 0.0, 'compound': -0.25}\n",
      "{'neg': 0.087, 'neu': 0.913, 'pos': 0.0, 'compound': -0.25}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.867, 'pos': 0.133, 'compound': 0.25}\n",
      "{'neg': 0.0, 'neu': 0.92, 'pos': 0.08, 'compound': 0.0772}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.119, 'neu': 0.881, 'pos': 0.0, 'compound': -0.3182}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.93, 'pos': 0.07, 'compound': 0.128}\n",
      "{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.5574}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.1, 'neu': 0.9, 'pos': 0.0, 'compound': -0.25}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.5859}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.1, 'neu': 0.9, 'pos': 0.0, 'compound': -0.2732}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.884, 'pos': 0.116, 'compound': 0.3612}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.5849}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.087, 'neu': 0.913, 'pos': 0.0, 'compound': -0.2732}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.5849}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.5849}\n",
      "{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.5849}\n",
      "{'neg': 0.0, 'neu': 0.789, 'pos': 0.211, 'compound': 0.34}\n",
      "{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.5849}\n",
      "{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.5849}\n",
      "{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.5849}\n",
      "{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.5849}\n",
      "{'neg': 0.161, 'neu': 0.839, 'pos': 0.0, 'compound': -0.4376}\n",
      "{'neg': 0.177, 'neu': 0.823, 'pos': 0.0, 'compound': -0.6486}\n",
      "{'neg': 0.105, 'neu': 0.895, 'pos': 0.0, 'compound': -0.25}\n",
      "{'neg': 0.0, 'neu': 0.914, 'pos': 0.086, 'compound': 0.1511}\n",
      "{'neg': 0.138, 'neu': 0.862, 'pos': 0.0, 'compound': -0.4939}\n",
      "{'neg': 0.282, 'neu': 0.513, 'pos': 0.205, 'compound': -0.3612}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.5849}\n",
      "{'neg': 0.272, 'neu': 0.728, 'pos': 0.0, 'compound': -0.7964}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.153, 'neu': 0.847, 'pos': 0.0, 'compound': -0.5849}\n",
      "{'neg': 0.174, 'neu': 0.826, 'pos': 0.0, 'compound': -0.5849}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.198, 'neu': 0.621, 'pos': 0.181, 'compound': -0.0772}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.772, 'pos': 0.228, 'compound': 0.7096}\n",
      "{'neg': 0.0, 'neu': 0.889, 'pos': 0.111, 'compound': 0.3612}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.878, 'pos': 0.122, 'compound': 0.3612}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'compound': 0.4019}\n",
      "{'neg': 0.087, 'neu': 0.913, 'pos': 0.0, 'compound': -0.296}\n",
      "{'neg': 0.153, 'neu': 0.596, 'pos': 0.251, 'compound': 0.2394}\n",
      "{'neg': 0.091, 'neu': 0.909, 'pos': 0.0, 'compound': -0.25}\n",
      "{'neg': 0.1, 'neu': 0.9, 'pos': 0.0, 'compound': -0.25}\n"
     ]
    }
   ],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "for index, tweet in tweet_df.head(100).iterrows():\n",
    "    score = analyser.polarity_scores(tweet.text)\n",
    "    print(f\"{str(score)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
